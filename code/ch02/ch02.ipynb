{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2장. 간단한 분류 알고리즘 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**아래 링크를 통해 이 노트북을 주피터 노트북 뷰어(nbviewer.jupyter.org)로 보거나 구글 코랩(colab.research.google.com)에서 실행할 수 있습니다.**\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/rickiepark/python-machine-learning-book-2nd-edition/blob/master/code/ch02/ch02.ipynb\"><img src=\"https://jupyter.org/assets/main-logo.svg\" width=\"28\" />주피터 노트북 뷰어로 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/python-machine-learning-book-2nd-edition/blob/master/code/ch02/ch02.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`watermark`는 주피터 노트북에 사용하는 파이썬 패키지를 출력하기 위한 유틸리티입니다. `watermark` 패키지를 설치하려면 다음 셀의 주석을 제거한 뒤 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -u -d -p numpy,pandas,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이썬으로 퍼셉트론 학습 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 객체 지향 퍼셉트론 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron(object):\n",
    "    \"\"\"퍼셉트론 분류기\n",
    "\n",
    "    매개변수\n",
    "    ------------\n",
    "    eta : float\n",
    "      학습률 (0.0과 1.0 사이)\n",
    "    n_iter : int\n",
    "      훈련 데이터셋 반복 횟수\n",
    "    random_state : int\n",
    "      가중치 무작위 초기화를 위한 난수 생성기 시드\n",
    "\n",
    "    속성\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      학습된 가중치\n",
    "    errors_ : list\n",
    "      에포크마다 누적된 분류 오류\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"훈련 데이터 학습\n",
    "\n",
    "        매개변수\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          n_samples개의 샘플과 n_features개의 특성으로 이루어진 훈련 데이터\n",
    "        y : array-like, shape = [n_samples]\n",
    "          타깃값\n",
    "\n",
    "        반환값\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "        \n",
    "        print(f\"X shape={X.shape}, y shape={y.shape}\")\n",
    "\n",
    "        for it in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                # target과 self.predict(xi)가 달라서 학습이 된 횟수 세기\n",
    "                errors += int(update != 0.0)\n",
    "            print(f\"iter {it}: error: {errors}\")\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"최종 입력 계산\"\"\"\n",
    "        # [n_samples, n_features] x [n_features, 1] = [n_samples, 1]\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"단위 계단 함수를 사용하여 클래스 레이블을 반환합니다\"\"\"\n",
    "        # np.where(condition, if-true-value, else-value)\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1, 2, 3])\n",
    "v2 = 0.5 * v1\n",
    "np.arccos(v1.dot(v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rgen은 무엇?\n",
    "<https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.RandomState.html>  \n",
    "<https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.RandomState.normal.html#numpy.random.RandomState.normal>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 1\n",
    "std = 0.1\n",
    "print(f\"generate normally distributed random values with mean={mean}, std={std}\")\n",
    "\n",
    "print(\"\\nwith FIXED random seed\")\n",
    "for i in range(5):\n",
    "    # RandomState에 들어가는 seed 값 고정\n",
    "    rgen = np.random.RandomState(1)\n",
    "    w_ = rgen.normal(loc=mean, scale=std, size=5)\n",
    "    print(w_)\n",
    "\n",
    "print(\"\\nwith VARYING random seed\")\n",
    "for i in range(5):\n",
    "    # RandomState에 들어가는 seed 값 변화\n",
    "    rgen = np.random.RandomState(i)\n",
    "    w_ = rgen.normal(loc=0.0, scale=0.01, size=5)\n",
    "    print(w_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 붓꽃 데이터셋에서 퍼셉트론 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 붓꽃 데이터셋 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# url을 로컬 경로로 수정\n",
    "df = pd.read_csv('iris.data', header=None)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns = {0: \"calyx_length\", 1: \"calyx_width\", 2: \"petal_length\", \n",
    "                          3: \"petal_width\", 4: \"label\"})\n",
    "# 행을 20개마다 하나씩 출력\n",
    "df.iloc[0:-1:20, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노트:\n",
    "\n",
    "이 깃허브에는 붓꽃 데이터셋이 포함되어 있습니다(이 책에서 사용하는 다른 데이터셋도 모두 포함되어 있습니다). 인터넷에 연결되어 있지 않거나 이따금 UCI 서버(https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data)에 접근할 수 없을 때 사용할 수 있습니다. 이런 경우 로컬 디렉터리에서 붓꽃 데이터를 로드하려면 다음 코드를\n",
    "```python\n",
    "    df = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "        'machine-learning-databases/iris/iris.data', header=None)\n",
    "```\n",
    "다음과 같이 바꿉니다.\n",
    "```python \n",
    "    df = pd.read_csv('your/local/path/to/iris.data', header=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 붓꽃 데이터 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# setosa와 versicolor를 선택합니다 row:0~100, column:4\n",
    "y = df.iloc[0:100, 4].values\n",
    "y = np.where(y == 'Iris-setosa', -1, 1)\n",
    "\n",
    "# 꽃받침 길이와 꽃잎 길이를 추출합니다\n",
    "# .values 를 붙이면 dataframe 데이터를 numpy array로 변환해줌\n",
    "X = df.iloc[0:100, [0, 2]].values\n",
    "\n",
    "print(f\"X shape={X.shape}, y shape={y.shape}\")\n",
    "\n",
    "# 산점도를 그립니다\n",
    "plt.scatter(X[:50, 0], X[:50, 1],\n",
    "            color='red', marker='o', label='setosa')\n",
    "plt.scatter(X[50:100, 0], X[50:100, 1],\n",
    "            color='blue', marker='x', label='versicolor')\n",
    "\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퍼셉트론 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppn = Perceptron(eta=0.1, n_iter=10)\n",
    "\n",
    "ppn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(ppn.errors_) + 1), ppn.errors_, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of errors')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 경계 그래프 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "\n",
    "    # 마커와 컬러맵을 설정합니다\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # 결정 경계를 그립니다\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # 샘플의 산점도를 그립니다\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X, y, classifier=ppn)\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 적응형 선형 뉴런과 학습의 수렴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이썬으로 아달린 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineGD(object):\n",
    "    \"\"\"적응형 선형 뉴런 분류기\n",
    "\n",
    "    매개변수\n",
    "    ------------\n",
    "    eta : float\n",
    "      학습률 (0.0과 1.0 사이)\n",
    "    n_iter : int\n",
    "      훈련 데이터셋 반복 횟수\n",
    "    random_state : int\n",
    "      가중치 무작위 초기화를 위한 난수 생성기 시드\n",
    "\n",
    "    속성\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      학습된 가중치\n",
    "    cost_ : list\n",
    "      에포크마다 누적된 비용 함수의 제곱합\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"훈련 데이터 학습\n",
    "\n",
    "        매개변수\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          n_samples 개의 샘플과 n_features 개의 특성으로 이루어진 훈련 데이터\n",
    "        y : array-like, shape = [n_samples]\n",
    "          타깃값\n",
    "\n",
    "        반환값\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            # Please note that the \"activation\" method has no effect\n",
    "            # in the code since it is simply an identity function. We\n",
    "            # could write `output = self.net_input(X)` directly instead.\n",
    "            # The purpose of the activation is more conceptual, i.e.,  \n",
    "            # in the case of logistic regression (as we will see later), \n",
    "            # we could change it to\n",
    "            # a sigmoid function to implement a logistic regression classifier.\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            # X.T : X transpose\n",
    "            # X.T * errors: [n_features, n_samples] x [n_samples, 1] = [n_features, 1]\n",
    "            # sig\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"최종 입력 계산\"\"\"\n",
    "        # [n_samples, n_features] x [n_features, 1] = [n_samples, 1]\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"선형 활성화 계산\"\"\"\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"단위 계단 함수를 사용하여 클래스 레이블을 반환합니다\"\"\"\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "\n",
    "ada1 = AdalineGD(n_iter=10, eta=0.01).fit(X, y)\n",
    "ax[0].plot(range(1, len(ada1.cost_) + 1), np.log10(ada1.cost_), marker='o')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('log(Sum-squared-error)')\n",
    "ax[0].set_title('Adaline - Learning rate 0.01')\n",
    "\n",
    "ada2 = AdalineGD(n_iter=10, eta=0.0001).fit(X, y)\n",
    "ax[1].plot(range(1, len(ada2.cost_) + 1), ada2.cost_, marker='o')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Sum-squared-error')\n",
    "ax[1].set_title('Adaline - Learning rate 0.0001')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특성 스케일을 조정하여 경사 하강법 결과 향상시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성을 표준화합니다.\n",
    "X_std = np.copy(X)\n",
    "X_std[:, 0] = (X[:, 0] - X[:, 0].mean()) / X[:, 0].std()\n",
    "X_std[:, 1] = (X[:, 1] - X[:, 1].mean()) / X[:, 1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdalineGD(n_iter=15, eta=0.01)\n",
    "ada.fit(X_std, y)\n",
    "\n",
    "plot_decision_regions(X_std, y, classifier=ada)\n",
    "plt.title('Adaline - Gradient Descent')\n",
    "plt.xlabel('sepal length [standardized]')\n",
    "plt.ylabel('petal length [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len(ada.cost_) + 1), ada.cost_, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Sum-squared-error')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대규모 머신 러닝과 확률적 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineSGD(object):\n",
    "    \"\"\"ADAptive LInear NEuron 분류기\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      학습률 (0.0과 1.0 사이)\n",
    "    n_iter : int\n",
    "      훈련 데이터셋 반복 횟수\n",
    "    shuffle : bool (default: True)\n",
    "      True로 설정하면 같은 반복이 되지 않도록 에포크마다 훈련 데이터를 섞습니다\n",
    "    random_state : int\n",
    "      가중치 무작위 초기화를 위한 난수 생성기 시드\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      학습된 가중치\n",
    "    cost_ : list\n",
    "      모든 훈련 샘플에 대해 에포크마다 누적된 평균 비용 함수의 제곱합\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=10, shuffle=True, random_state=None):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.w_initialized = False\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"훈련 데이터 학습\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          n_samples 개의 샘플과 n_features 개의 특성으로 이루어진 훈련 데이터\n",
    "        y : array-like, shape = [n_samples]\n",
    "          타깃 벡터\n",
    "\n",
    "        반환값\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        self._initialize_weights(X.shape[1])\n",
    "        self.cost_ = []\n",
    "        for i in range(self.n_iter):\n",
    "            if self.shuffle:\n",
    "                X, y = self._shuffle(X, y)\n",
    "            cost = []\n",
    "            for xi, target in zip(X, y):\n",
    "                cost.append(self._update_weights(xi, target))\n",
    "            avg_cost = sum(cost) / len(y)\n",
    "            self.cost_.append(avg_cost)\n",
    "        return self\n",
    "\n",
    "    def partial_fit(self, X, y):\n",
    "        \"\"\"가중치를 다시 초기화하지 않고 훈련 데이터를 학습합니다\"\"\"\n",
    "        if not self.w_initialized:\n",
    "            self._initialize_weights(X.shape[1])\n",
    "        if y.ravel().shape[0] > 1:\n",
    "            for xi, target in zip(X, y):\n",
    "                self._update_weights(xi, target)\n",
    "        else:\n",
    "            self._update_weights(X, y)\n",
    "        return self\n",
    "\n",
    "    def _shuffle(self, X, y):\n",
    "        \"\"\"훈련 데이터를 섞습니다\"\"\"\n",
    "        r = self.rgen.permutation(len(y))\n",
    "        return X[r], y[r]\n",
    "    \n",
    "    def _initialize_weights(self, m):\n",
    "        \"\"\"랜덤한 작은 수로 가중치를 초기화합니다\"\"\"\n",
    "        self.rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = self.rgen.normal(loc=0.0, scale=0.01, size=1 + m)\n",
    "        self.w_initialized = True\n",
    "        \n",
    "    def _update_weights(self, xi, target):\n",
    "        \"\"\"아달린 학습 규칙을 적용하여 가중치를 업데이트합니다\"\"\"\n",
    "        output = self.activation(self.net_input(xi))\n",
    "        error = (target - output)\n",
    "        self.w_[1:] += self.eta * xi.dot(error)\n",
    "        self.w_[0] += self.eta * error\n",
    "        cost = 0.5 * error**2\n",
    "        return cost\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"최종 입력 계산\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"선형 활성화 계산\"\"\"\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"단위 계단 함수를 사용하여 클래스 레이블을 반환합니다\"\"\"\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdalineSGD(n_iter=15, eta=0.01, random_state=1)\n",
    "ada.fit(X_std, y)\n",
    "\n",
    "plot_decision_regions(X_std, y, classifier=ada)\n",
    "plt.title('Adaline - Stochastic Gradient Descent')\n",
    "plt.xlabel('sepal length [standardized]')\n",
    "plt.ylabel('petal length [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len(ada.cost_) + 1), ada.cost_, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Average Cost')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
